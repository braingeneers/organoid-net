{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier on Simulated Data\n",
    "\n",
    "Train a classifier on Alex's [simulated data](https://github.com/braingeneers/braingeneers/issues/3). The simulated PNG's with labels have been converted into Tensorflow's native binary format, tfrecords via an [ingest notebook](https://github.com/braingeneers/organoid-net/blob/master/simulated/ingest.ipynb) and stored in the PRP S3/CEPH store so they are publicly accesible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n",
      "DEBUG: ON\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)  # reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "# DistributionStrategy is not supported when eager execution is enabled...sigh....\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# See if we have a GPU - if not check Edit->Notebook Settings for GPU/TPU options\n",
    "# In a prelimary test the GPU took ~2.5 minutes to train vs. ~4-5 minutes for the TPU,\n",
    "# but the TPU required less power and therefore is the green choice :-)\n",
    "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
    "\n",
    "# TF outputs quite a bit of logging form TFDataset when sourcing from S3\n",
    "# 0=All, 1=Filter Info, 2=Filter Warning, 3=Filter Error\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "# Simple syntatic sugar for debug vs. train parameters\n",
    "def debug(debug_param, no_debug_param):\n",
    "    return debug_param if os.environ.get(\"DEBUG\") else no_debug_param\n",
    "print(debug(\"DEBUG: ON\", \"DEBUG: OFF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Profile: prp Endpoint: https://s3.nautilus.optiputer.net Bucket: braingeneers\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = \"braingeneers\"\n",
    "\n",
    "session = boto3.session.Session(profile_name=os.getenv(\"AWS_PROFILE\"))\n",
    "bucket = session.resource(\n",
    "    \"s3\", endpoint_url=os.getenv(\"AWS_S3_ENDPOINT\")).Bucket(bucket_name)\n",
    "print(\"S3 Profile: {} Endpoint: {} Bucket: {}\".format(\n",
    "    os.getenv(\"AWS_PROFILE\"), os.getenv(\"AWS_S3_ENDPOINT\"), bucket_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading simulated dataset\n",
      "Dataset metadata keys: ['image_width', 'image_height', 'labels', 'description', 'data_set', 'train_examples_name', 'num_train_examples', 'test_examples_name', 'num_test_examples']\n",
      "8000 train and 2000 test samples with 49 labels\n"
     ]
    }
   ],
   "source": [
    "# Read in metadata for a dataset\n",
    "dataset_name = \"simulated\"\n",
    "print(\"Reading {} dataset\".format(dataset_name))\n",
    "\n",
    "metadata = json.loads(bucket.Object(\n",
    "    dataset_name + \"/metadata.json\").get()['Body'].read().decode('utf-8'))\n",
    "print(\"Dataset metadata keys:\", list(metadata.keys()))\n",
    "print(\"{} train and {} test samples with {} labels\".format(\n",
    "    metadata[\"num_train_examples\"], metadata[\"num_test_examples\"], len(metadata[\"labels\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Flow Dataset\n",
    "\n",
    "For this small of a dataset this is overkill. But it demonstrates how to build a lazy data pipeline with data modification such that it will feed the Tensorflow engine natively at training time. Data augmentation via tf.image.* can easily be added and this general pattern will likely be useful when we have big data sets and video in PRP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image shape: (87, 115, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4602b75f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def parse_one_example(example):\n",
    "    example = tf.parse_single_example(example, features = {\n",
    "        \"example\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "    \n",
    "    image = tf.image.decode_png(example[\"example\"], channels=1)\n",
    "    image = tf.image.resize_images(\n",
    "        image, [metadata[\"image_height\"] // 4, metadata[\"image_width\"] // 4])\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    label = tf.one_hot(example[\"label\"], len(metadata[\"labels\"]))\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def create_dataset(files, batch_size, num_classes):\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    dataset = dataset.map(parse_one_example, num_parallel_calls=8)\n",
    "    dataset.cache(\"tensorflow.cache\")\n",
    "    dataset = dataset.shuffle(8 * num_classes)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "training_dataset = create_dataset(\n",
    "    [\"s3://braingeneers/{}/{}\".format(metadata[\"data_set\"], metadata[\"train_examples_name\"])],\n",
    "    batch_size, len(metadata[\"labels\"]))\n",
    "test_dataset = create_dataset(\n",
    "    [\"s3://braingeneers/{}/{}\".format(metadata[\"data_set\"], metadata[\"test_examples_name\"])],\n",
    "    batch_size, len(metadata[\"labels\"]))\n",
    "\n",
    "# # Display the first image of a batch as a check\n",
    "examples, labels = training_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Non Eager Mode\n",
    "with tf.Session() as sess:\n",
    "    first_image = sess.run(examples)[0]\n",
    "\n",
    "# Eager Mode\n",
    "# first_image = examples[0].numpy()\n",
    "    \n",
    "print(\"First image shape:\", first_image.shape)\n",
    "plt.imshow(first_image.reshape(first_image.shape[0], first_image.shape[1]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/mbernico/deep_learning_quick_reference/blob/master/chapter_6/mnist_hyperband_search.py\n",
    "import numpy as np\n",
    "import random\n",
    "from math import log, ceil\n",
    "from time import time, ctime\n",
    "\n",
    "class Hyperband:\n",
    "    def __init__(self, data, get_params_function, try_params_function, max_iter=81):\n",
    "        self.data = data\n",
    "        self.get_params = get_params_function\n",
    "        self.try_params = try_params_function\n",
    "\n",
    "        self.max_iter = max_iter  # maximum iterations per configuration\n",
    "        self.eta = 3  # defines configuration downsampling rate (default = 3)\n",
    "\n",
    "        self.logeta = lambda x: log(x) / log(self.eta)\n",
    "        self.s_max = int(self.logeta(self.max_iter))\n",
    "        self.B = (self.s_max + 1) * self.max_iter\n",
    "\n",
    "        self.results = []  # list of dicts\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.best_counter = -1\n",
    "\n",
    "    # can be called multiple times\n",
    "    def run(self, skip_last=0):\n",
    "\n",
    "        for s in list(reversed(range(self.s_max + 1)))[:1 if os.environ.get(\"DEBUG\") else -1]:\n",
    "\n",
    "            # initial number of configurations\n",
    "            n = int(ceil(self.B / self.max_iter / (s + 1) * self.eta ** s))\n",
    "\n",
    "            # initial number of iterations per config\n",
    "            r = self.max_iter * self.eta ** (-s)\n",
    "\n",
    "            # n random configurations\n",
    "            T = [self.get_params() for i in range(n)]\n",
    "\n",
    "            for i in list(range((s + 1) - int(skip_last)))[:1 if os.environ.get(\"DEBUG\") else -1]:  # changed from s + 1\n",
    "\n",
    "                # Run each of the n configs for <iterations>\n",
    "                # and keep best (n_configs / eta) configurations\n",
    "\n",
    "                n_configs = n * self.eta ** (-i)\n",
    "                n_iterations = r * self.eta ** (i)\n",
    "\n",
    "                print(\"\\n*** {} configurations x {:.1f} iterations each\".format(\n",
    "                    n_configs, n_iterations))\n",
    "\n",
    "                val_losses = []\n",
    "                early_stops = []\n",
    "\n",
    "                for t in T[:1 if os.environ.get(\"DEBUG\") else -1]:\n",
    "\n",
    "                    self.counter += 1\n",
    "                    print(\"\\n{} | {} | lowest loss so far: {:.4f} (run {})\\n\".format(\n",
    "                        self.counter, ctime(), self.best_loss, self.best_counter))\n",
    "\n",
    "                    start_time = time()\n",
    "\n",
    "                    result = self.try_params(self.data, n_iterations, t)\n",
    "\n",
    "                    assert (type(result) == dict)\n",
    "                    assert ('loss' in result)\n",
    "\n",
    "                    seconds = int(round(time() - start_time))\n",
    "                    print(\"\\n{} seconds.\".format(seconds))\n",
    "\n",
    "                    loss = result['loss']\n",
    "                    val_losses.append(loss)\n",
    "\n",
    "                    early_stop = result.get('early_stop', False)\n",
    "                    early_stops.append(early_stop)\n",
    "\n",
    "                    # keeping track of the best result so far (for display only)\n",
    "                    # could do it be checking results each time, but hey\n",
    "                    if loss < self.best_loss:\n",
    "                        self.best_loss = loss\n",
    "                        self.best_counter = self.counter\n",
    "\n",
    "                    result['counter'] = self.counter\n",
    "                    result['seconds'] = seconds\n",
    "                    result['params'] = t\n",
    "                    result['iterations'] = n_iterations\n",
    "                    result['num_model_params'] = result['model'].count_params()\n",
    "                    del result['model']\n",
    "\n",
    "                    self.results.append(result)\n",
    "\n",
    "                # select a number of best configurations for the next loop\n",
    "                # filter out early stops, if any\n",
    "                indices = np.argsort(val_losses)\n",
    "                T = [T[i] for i in indices if not early_stops[i]]\n",
    "                T = T[0:int(n_configs / self.eta)]\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** 81 configurations x 1.0 iterations each\n",
      "\n",
      "1 | Sat Nov 10 14:52:42 2018 | lowest loss so far: inf (run -1)\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 87, 115, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 85, 113, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 42, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 42, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 75264)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 75264)             301056    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 49)                3687985   \n",
      "=================================================================\n",
      "Total params: 3,989,361\n",
      "Trainable params: 3,838,833\n",
      "Non-trainable params: 150,528\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 152s 2s/step - loss: 0.1441 - acc: 0.9665\n",
      "[0.09144964814186096, 0.9921875]\n",
      "\n",
      "162 seconds.\n",
      "Completed training.\n",
      "Top hyperparameter combinations:\n",
      "{'seconds': 162, 'iterations': 1.0, 'counter': 1, 'num_model_params': 3989361, 'params': {'width': 32}, 'loss': 0.09144964814186096}\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape, output_shape, hyperparameters={\"width\": 64}):\n",
    "    input_layer = tf.keras.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "#     x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(input_layer)\n",
    "#     x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "#     x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "#     x = tf.keras.layers.Dropout(0.25)(x)\n",
    "#     x = tf.keras.layers.Flatten()(x)\n",
    "#     x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "#     x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(hyperparameters[\"width\"], (3, 3), activation=\"relu\")(input_layer)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)   \n",
    "#     x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "#     x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(output_shape, activation=\"softmax\", name=\"output\")(x)\n",
    "        \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # if os.environ.get(\"DEBUG\"):\n",
    "    #     model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "    #                   metrics=['accuracy'],\n",
    "    #                   optimizer=tf.train.AdamOptimizer())\n",
    "    # # Can's use the keras version as it doesn't support distribution strategies yet\n",
    "    # #                   optimizer=tf.keras.optimizers.Adam())\n",
    "    # else:\n",
    "    #     model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "    #                   metrics=['accuracy'],\n",
    "    #                   optimizer=tf.train.AdamOptimizer(),\n",
    "    #                   distribute=tf.contrib.distribute.MirroredStrategy())\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=tf.keras.optimizers.Adam())\n",
    "    return model\n",
    "\n",
    "def get_hyperparameters():\n",
    "    return {\n",
    "        \"width\": random.choice([16, 32])\n",
    "    }\n",
    "\n",
    "def try_params(data, num_iters, hyperparameters):\n",
    "    model = create_model(input_shape=(first_image.shape[0], first_image.shape[1], 1),\n",
    "                         output_shape=len(metadata[\"labels\"]), hyperparameters=hyperparameters)\n",
    "\n",
    "    if os.environ.get(\"DEBUG\"):\n",
    "        model.summary()\n",
    "        \n",
    "    model.fit(data[\"train\"], epochs=int(num_iters), verbose=1, \n",
    "              steps_per_epoch=metadata[\"num_train_examples\"] // batch_size,\n",
    "              callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, verbose=0, mode='auto')])\n",
    "\n",
    "    loss = model.evaluate(data[\"test\"], steps=1, verbose=0)\n",
    "    print(loss)\n",
    "    return {\"loss\": loss[0], \"model\": model}\n",
    "\n",
    "data = {\"train\": training_dataset, \"val\": training_dataset, \"test\": test_dataset,}\n",
    "hyperband = Hyperband(data, get_hyperparameters, try_params)\n",
    "results = hyperband.run()\n",
    "\n",
    "print(\"Completed training.\")\n",
    "\n",
    "print(\"Top hyperparameter combinations:\")\n",
    "print(sorted(results, key=lambda r: r[\"loss\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and params to bucket braingeneers under rcurrie/simulated/models\n"
     ]
    }
   ],
   "source": [
    "# Save the params, model and weights to S3 for evaluation back on jupyter\n",
    "params = {\n",
    "    \"hyperparamters\": results\n",
    "}\n",
    "\n",
    "dest = \"{}/{}/models\".format(os.environ[\"USER\"], metadata[\"data_set\"])\n",
    "bucket.Object(\"{}/params.json\".format(dest)).put(Body=json.dumps(params), ACL=\"public-read\")\n",
    "# model.save(\"/tmp/model.h5\")\n",
    "# bucket.Object(\"{}/model.h5\".format(dest)).upload_file(\"/tmp/model.h5\", ExtraArgs={\"ACL\":\"public-read\"})\n",
    "print(\"Saved model and params to bucket {} under {}\".format(bucket_name, dest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
