{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier on Simulated Data\n",
    "\n",
    "Train a classifier on Alex's [simulated data](https://github.com/braingeneers/braingeneers/issues/3). The simulated PNG's with labels have been converted into Tensorflow's native binary format, tfrecords via an [ingest notebook](https://github.com/braingeneers/organoid-net/blob/master/simulated/ingest.ipynb) and stored in the PRP S3/CEPH store so they are publicly accesible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n",
      "S3_ENDPOINT: s3.nautilus.optiputer.net\n",
      "DEBUG: ON\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# DistributionStrategy is not supported when eager execution is enabled...sigh....\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "np.random.seed(42)  # reproducibility\n",
    "\n",
    "# See if we have a GPU - if not check Edit->Notebook Settings for GPU/TPU options\n",
    "# In a prelimary test the GPU took ~2.5 minutes to train vs. ~4-5 minutes for the TPU,\n",
    "# but the TPU required less power and therefore is the green choice :-)\n",
    "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
    "\n",
    "# Set so that Tensorflow can pull from the PRP S3/CEPH storage cluster\n",
    "# Check if already set as when running in k8s we'll set a local\n",
    "# endpoint so we can pull from multiple OSD's in parallel\n",
    "if \"S3_ENDPOINT\" not in os.environ:\n",
    "    os.environ[\"S3_ENDPOINT\"] = \"s3.nautilus.optiputer.net\"\n",
    "print(\"S3_ENDPOINT:\", os.environ[\"S3_ENDPOINT\"])\n",
    "\n",
    "# Simple syntatic sugar for debug vs. train parameters\n",
    "def debug(debug_param, no_debug_param):\n",
    "    return debug_param if os.environ.get(\"DEBUG\") else no_debug_param\n",
    "print(debug(\"DEBUG: ON\", \"DEBUG: OFF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_train_examples', 'description', 'data_set', 'image_width', 'labels', 'test_examples_name', 'num_test_examples', 'image_height', 'train_examples_name'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata about the dataset\n",
    "metadata = requests.get(\"https://s3.nautilus.optiputer.net/braingeneers/fashion-mnist/metadata.json\").json()\n",
    "# metadata = requests.get(\"https://s3.nautilus.optiputer.net/braingeneers/simulated/metadata.json\").json()\n",
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model params - we'll store final hyper parameters here as well\n",
    "params = {\"batch_size\": 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Flow Dataset\n",
    "\n",
    "For this small of a dataset this is overkill. But it demonstrates how to build a lazy data pipeline with data modification such that it will feed the Tensorflow engine natively at training time. Data augmentation via tf.image.* can easily be added and this general pattern will likely be useful when we have big data sets and video in PRP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image shape: (28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa0a1044c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_one_example(example):\n",
    "    example = tf.parse_single_example(example, features = {\n",
    "        \"example\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "    \n",
    "    image = tf.image.decode_png(example[\"example\"], channels=1)\n",
    "#     image = tf.image.resize_images(\n",
    "#         image, [metadata[\"image_height\"] // 8, metadata[\"image_width\"] // 8])\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    label = tf.one_hot(example[\"label\"], len(metadata[\"labels\"]))\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def create_dataset(files, batch_size, num_classes):\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    dataset = dataset.map(parse_one_example)\n",
    "    dataset = dataset.map(parse_one_example, num_parallel_calls=8)\n",
    "    dataset.cache(\"tensorflow.cache\")\n",
    "    dataset = dataset.shuffle(8 * num_classes)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "training_dataset = create_dataset(\n",
    "    [\"s3://braingeneers/{}/{}\".format(metadata[\"data_set\"], metadata[\"train_examples_name\"])],\n",
    "    params[\"batch_size\"], len(metadata[\"labels\"]))\n",
    "test_dataset = create_dataset(\n",
    "    [\"s3://braingeneers/{}/{}\".format(metadata[\"data_set\"], metadata[\"test_examples_name\"])],\n",
    "    params[\"batch_size\"], len(metadata[\"labels\"]))\n",
    "\n",
    "# # Display the first image of a batch as a check\n",
    "examples, labels = training_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Non Eager Mode\n",
    "with tf.Session() as sess:\n",
    "    first_image = sess.run(examples)[0]\n",
    "\n",
    "# Eager Mode\n",
    "# first_image = examples[0].numpy()\n",
    "    \n",
    "print(\"First image shape:\", first_image.shape)\n",
    "plt.imshow(first_image.reshape(first_image.shape[0], first_image.shape[1]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Train\n",
    "\n",
    "Copied directly from googles [MNIST on Keras](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) hello world which achieves very high accuracy on MNIST...not so much here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 6s 632ms/step - loss: 2.3304 - acc: 0.1250\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "Test loss 2.317080020904541 accuracy: 0.125\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape, output_shape):\n",
    "    input_layer = tf.keras.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(input_layer)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(output_shape, activation=\"softmax\", name=\"output\")(x)\n",
    "        \n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = create_model(input_shape=(first_image.shape[0], first_image.shape[1], 1),\n",
    "                     output_shape=len(metadata[\"labels\"]))\n",
    "\n",
    "\n",
    "if os.environ.get(\"DEBUG\"):\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=tf.train.AdadeltaOptimizer())\n",
    "else:\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=tf.train.AdadeltaOptimizer(),\n",
    "                  distribute=tf.contrib.distribute.MirroredStrategy())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train using multiple GPUS: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute\n",
    "model.fit(training_dataset, epochs=debug(1, 10), verbose=1, \n",
    "          steps_per_epoch=debug(10, metadata[\"num_train_examples\"] // params[\"batch_size\"]))\n",
    "\n",
    "score = model.evaluate(test_dataset, steps=1, verbose=1)\n",
    "print(\"Test loss\", score[0], \"accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
